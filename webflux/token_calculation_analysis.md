# WebFlux ê¸°ë°˜ í† í°ëŸ‰ ê³„ì‚° ê¸°ëŠ¥ ì¶”ê°€ ë°©ì•ˆ

## ğŸ¯ í† í°ëŸ‰ ê³„ì‚°ì´ í•„ìš”í•œ ì´ìœ 

1. **ë¹„ìš© ê´€ë¦¬**: LLM API ì‚¬ìš©ëŸ‰ ê¸°ë°˜ ê³¼ê¸ˆ
2. **ì‚¬ìš©ëŸ‰ ì œí•œ**: ì‚¬ìš©ìë³„/ì„¸ì…˜ë³„ í† í° í•œë„ ê´€ë¦¬
3. **ì„±ëŠ¥ ìµœì í™”**: í† í° ìˆ˜ì— ë”°ë¥¸ ì‘ë‹µ ì‹œê°„ ì˜ˆì¸¡
4. **í†µê³„ ìˆ˜ì§‘**: ì‚¬ìš© íŒ¨í„´ ë¶„ì„ ë° ë¦¬í¬íŠ¸

## ğŸ”§ êµ¬í˜„ ê°€ëŠ¥í•œ ë°©ë²•ë“¤

### Method 1: **OpenAI Tiktoken ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©** (ì¶”ì²œ)
```java
// ì˜ì¡´ì„± ì¶”ê°€ (build.gradle)
implementation 'com.knuddels:jtokkit:0.6.1'
```

### Method 2: **ì™¸ë¶€ í† í¬ë‚˜ì´ì € API í˜¸ì¶œ** (WebFlux í™œìš©)
- Hugging Face Tokenizer API
- OpenAI Tokenizer API
- ìì²´ í† í¬ë‚˜ì´ì € ì„œë²„

### Method 3: **ë¡œì»¬ í† í¬ë‚˜ì´ì € êµ¬í˜„**
- BPE (Byte-Pair Encoding) êµ¬í˜„
- SentencePiece í†µí•©

## ğŸš€ WebFluxë¥¼ í™œìš©í•œ êµ¬í˜„ ë°©ì•ˆ

### ë°©ì•ˆ 1: **ì™¸ë¶€ í† í¬ë‚˜ì´ì € APIì™€ WebFlux ì—°ë™**

#### ì¥ì 
- âœ… ë‹¤ì–‘í•œ ëª¨ë¸ì˜ í† í¬ë‚˜ì´ì € ì§€ì›
- âœ… ìµœì‹  í† í¬ë‚˜ì´ì € ìë™ ì—…ë°ì´íŠ¸
- âœ… WebFluxì˜ ë¹„ë™ê¸° ì²˜ë¦¬ í™œìš©
- âœ… ì—¬ëŸ¬ ìš”ì²­ ë³‘ë ¬ ì²˜ë¦¬ ê°€ëŠ¥

#### ë‹¨ì 
- âŒ ë„¤íŠ¸ì›Œí¬ ì˜ì¡´ì„±
- âŒ ì™¸ë¶€ ì„œë¹„ìŠ¤ ì¥ì•  ìœ„í—˜
- âŒ ì§€ì—° ì‹œê°„ ì¦ê°€

### ë°©ì•ˆ 2: **ë¡œì»¬ í† í¬ë‚˜ì´ì € + WebFlux ìŠ¤íŠ¸ë¦¬ë°**

#### ì¥ì 
- âœ… ë„¤íŠ¸ì›Œí¬ ë…ë¦½ì 
- âœ… ë¹ ë¥¸ ì²˜ë¦¬ ì†ë„
- âœ… ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™”
- âœ… WebFlux ìŠ¤íŠ¸ë¦¬ë° í™œìš©

#### ë‹¨ì 
- âŒ ëª¨ë¸ë³„ í† í¬ë‚˜ì´ì € ê´€ë¦¬ ë³µì¡
- âŒ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì˜ì¡´ì„±

## ğŸ’» êµ¬í˜„ ì˜ˆì‹œ

### 1. í† í° ê³„ì‚° ì„œë¹„ìŠ¤ ì¸í„°í˜ì´ìŠ¤
```java
public interface TokenCalculationService {
    
    // ë™ê¸° ë°©ì‹ (ê¸°ì¡´ íŒ¨í„´ ìœ ì§€)
    TokenInfo calculateTokens(String text, String model);
    
    // Reactive ë°©ì‹ (WebFlux í™œìš©)
    Mono<TokenInfo> calculateTokensReactive(String text, String model);
    
    // ë°°ì¹˜ ì²˜ë¦¬ (WebFlux ìŠ¤íŠ¸ë¦¬ë°)
    Flux<TokenInfo> calculateTokensBatch(List<String> texts, String model);
    
    // ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬
    Flux<TokenInfo> calculateTokensStream(Flux<String> textStream, String model);
}
```

### 2. í† í° ì •ë³´ DTO
```java
@Data
@Builder
public class TokenInfo {
    private String text;
    private String model;
    private int inputTokens;
    private int outputTokens;
    private int totalTokens;
    private double estimatedCost;
    private long processingTimeMs;
    private TokenizationMethod method;
    
    public enum TokenizationMethod {
        LOCAL_TIKTOKEN,
        HUGGINGFACE_API,
        OPENAI_API,
        SENTENCEPIECE
    }
}
```

### 3. ë¡œì»¬ í† í¬ë‚˜ì´ì € êµ¬í˜„ (Tiktoken)
```java
@Service
@Slf4j
public class LocalTokenCalculationService implements TokenCalculationService {
    
    private final Map<String, Encoding> encodingCache = new ConcurrentHashMap<>();
    
    @PostConstruct
    public void initializeEncodings() {
        // ì£¼ìš” ëª¨ë¸ë³„ ì¸ì½”ë”© ì´ˆê¸°í™”
        encodingCache.put("gpt-3.5-turbo", Encodings.newDefaultEncodingRegistry().getEncoding(EncodingType.CL100K_BASE));
        encodingCache.put("gpt-4", Encodings.newDefaultEncodingRegistry().getEncoding(EncodingType.CL100K_BASE));
        encodingCache.put("text-davinci-003", Encodings.newDefaultEncodingRegistry().getEncoding(EncodingType.P50K_BASE));
    }
    
    @Override
    public TokenInfo calculateTokens(String text, String model) {
        long startTime = System.currentTimeMillis();
        
        Encoding encoding = getEncodingForModel(model);
        List<Integer> tokens = encoding.encode(text);
        
        return TokenInfo.builder()
                .text(text.length() > 100 ? text.substring(0, 100) + "..." : text)
                .model(model)
                .inputTokens(tokens.size())
                .totalTokens(tokens.size())
                .estimatedCost(calculateCost(tokens.size(), model))
                .processingTimeMs(System.currentTimeMillis() - startTime)
                .method(TokenInfo.TokenizationMethod.LOCAL_TIKTOKEN)
                .build();
    }
    
    @Override
    public Mono<TokenInfo> calculateTokensReactive(String text, String model) {
        return Mono.fromCallable(() -> calculateTokens(text, model))
                .subscribeOn(Schedulers.boundedElastic()); // CPU ì§‘ì•½ì  ì‘ì—…ì„ ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ
    }
    
    @Override
    public Flux<TokenInfo> calculateTokensBatch(List<String> texts, String model) {
        return Flux.fromIterable(texts)
                .parallel() // ë³‘ë ¬ ì²˜ë¦¬
                .runOn(Schedulers.parallel())
                .map(text -> calculateTokens(text, model))
                .sequential();
    }
    
    @Override
    public Flux<TokenInfo> calculateTokensStream(Flux<String> textStream, String model) {
        return textStream
                .buffer(10) // 10ê°œì”© ë°°ì¹˜ ì²˜ë¦¬
                .flatMap(batch -> calculateTokensBatch(batch, model));
    }
    
    private Encoding getEncodingForModel(String model) {
        return encodingCache.getOrDefault(model, 
            encodingCache.get("gpt-3.5-turbo")); // ê¸°ë³¸ê°’
    }
    
    private double calculateCost(int tokens, String model) {
        // ëª¨ë¸ë³„ í† í°ë‹¹ ë¹„ìš© ê³„ì‚°
        Map<String, Double> costPerToken = Map.of(
            "gpt-3.5-turbo", 0.002 / 1000, // $0.002 per 1K tokens
            "gpt-4", 0.03 / 1000,          // $0.03 per 1K tokens
            "text-davinci-003", 0.02 / 1000
        );
        
        return tokens * costPerToken.getOrDefault(model, 0.002 / 1000);
    }
}
```

### 4. ì™¸ë¶€ API í† í¬ë‚˜ì´ì € êµ¬í˜„ (WebFlux í™œìš©)
```java
@Service
@Slf4j
public class ExternalTokenCalculationService implements TokenCalculationService {
    
    private final WebClient webClient;
    private final TokenCalculationConfig config;
    
    public ExternalTokenCalculationService(WebClient.Builder webClientBuilder, 
                                         TokenCalculationConfig config) {
        this.config = config;
        this.webClient = webClientBuilder
                .baseUrl(config.getHuggingFaceApiUrl())
                .defaultHeader("Authorization", "Bearer " + config.getApiToken())
                .build();
    }
    
    @Override
    public Mono<TokenInfo> calculateTokensReactive(String text, String model) {
        long startTime = System.currentTimeMillis();
        
        Map<String, Object> requestBody = Map.of(
            "inputs", text,
            "options", Map.of("use_cache", false)
        );
        
        return webClient
                .post()
                .uri("/models/{model}", getHuggingFaceModelName(model))
                .contentType(MediaType.APPLICATION_JSON)
                .bodyValue(requestBody)
                .retrieve()
                .bodyToMono(HuggingFaceTokenResponse.class)
                .map(response -> TokenInfo.builder()
                        .text(text.length() > 100 ? text.substring(0, 100) + "..." : text)
                        .model(model)
                        .inputTokens(response.getTokens().size())
                        .totalTokens(response.getTokens().size())
                        .estimatedCost(calculateCost(response.getTokens().size(), model))
                        .processingTimeMs(System.currentTimeMillis() - startTime)
                        .method(TokenInfo.TokenizationMethod.HUGGINGFACE_API)
                        .build())
                .timeout(Duration.ofSeconds(10))
                .onErrorResume(ex -> {
                    log.warn("External tokenizer failed, falling back to local: {}", ex.getMessage());
                    return calculateTokensReactive(text, model); // ë¡œì»¬ fallback
                });
    }
    
    @Override
    public Flux<TokenInfo> calculateTokensBatch(List<String> texts, String model) {
        return Flux.fromIterable(texts)
                .flatMap(text -> calculateTokensReactive(text, model), 5) // ë™ì‹œ ì²˜ë¦¬ ì œí•œ
                .onBackpressureBuffer(100); // ë°±í”„ë ˆì…” ì²˜ë¦¬
    }
    
    private String getHuggingFaceModelName(String model) {
        Map<String, String> modelMapping = Map.of(
            "gpt-3.5-turbo", "gpt2",
            "gpt-4", "gpt2",
            "claude", "bert-base-uncased"
        );
        return modelMapping.getOrDefault(model, "gpt2");
    }
}
```

### 5. í† í° ê³„ì‚° í†µí•© ì„œë¹„ìŠ¤
```java
@Service
@Slf4j
public class IntegratedTokenCalculationService {
    
    private final LocalTokenCalculationService localService;
    private final ExternalTokenCalculationService externalService;
    private final TokenCalculationConfig config;
    
    public Mono<TokenInfo> calculateTokens(String text, String model, boolean useExternal) {
        if (useExternal && config.isExternalApiEnabled()) {
            return externalService.calculateTokensReactive(text, model)
                    .onErrorResume(ex -> {
                        log.warn("External service failed, using local: {}", ex.getMessage());
                        return localService.calculateTokensReactive(text, model);
                    });
        } else {
            return localService.calculateTokensReactive(text, model);
        }
    }
    
    // í”„ë¡¬í”„íŠ¸ì™€ ì˜ˆìƒ ì‘ë‹µ í† í° ëª¨ë‘ ê³„ì‚°
    public Mono<TokenInfo> calculateRequestTokens(LLMRequest request) {
        String model = mapEngineToModel(request.getEngine());
        
        return calculateTokens(request.getPrompt(), model, false)
                .map(tokenInfo -> {
                    int maxResponseTokens = request.getMaxTokens() != null ? 
                            request.getMaxTokens() : 512;
                    
                    return TokenInfo.builder()
                            .text(tokenInfo.getText())
                            .model(model)
                            .inputTokens(tokenInfo.getInputTokens())
                            .outputTokens(maxResponseTokens)
                            .totalTokens(tokenInfo.getInputTokens() + maxResponseTokens)
                            .estimatedCost(tokenInfo.getEstimatedCost() + 
                                    calculateOutputCost(maxResponseTokens, model))
                            .processingTimeMs(tokenInfo.getProcessingTimeMs())
                            .method(tokenInfo.getMethod())
                            .build();
                });
    }
    
    private String mapEngineToModel(String engine) {
        Map<String, String> engineMapping = Map.of(
            "vllm", "gpt-3.5-turbo",
            "sglang", "gpt-4"
        );
        return engineMapping.getOrDefault(engine, "gpt-3.5-turbo");
    }
}
```

### 6. ì»¨íŠ¸ë¡¤ëŸ¬ì— í† í° ê³„ì‚° ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€
```java
@RestController
@RequestMapping("/api/tokens")
@RequiredArgsConstructor
@Slf4j
public class TokenController {
    
    private final IntegratedTokenCalculationService tokenService;
    
    @PostMapping("/calculate")
    public Mono<ResponseEntity<TokenInfo>> calculateTokens(
            @RequestBody TokenCalculationRequest request) {
        
        return tokenService.calculateTokens(
                request.getText(), 
                request.getModel(), 
                request.isUseExternal())
                .map(ResponseEntity::ok)
                .onErrorResume(ex -> {
                    log.error("Token calculation failed: {}", ex.getMessage());
                    return Mono.just(ResponseEntity.badRequest().build());
                });
    }
    
    @PostMapping("/calculate-batch")
    public Flux<TokenInfo> calculateTokensBatch(
            @RequestBody TokenBatchRequest request) {
        
        return tokenService.calculateTokensBatch(
                request.getTexts(), 
                request.getModel())
                .onBackpressureBuffer(1000);
    }
    
    @PostMapping("/estimate-request")
    public Mono<ResponseEntity<TokenInfo>> estimateRequestTokens(
            @RequestBody LLMRequest request) {
        
        return tokenService.calculateRequestTokens(request)
                .map(ResponseEntity::ok);
    }
}
```

### 7. LLM ì„œë¹„ìŠ¤ì— í† í° ê³„ì‚° í†µí•©
```java
@Service
@RequiredArgsConstructor
@Slf4j
public class EnhancedLLMService {
    
    private final LLMService originalLLMService;
    private final IntegratedTokenCalculationService tokenService;
    
    public Mono<LLMResponseWithTokens> generateResponseWithTokens(LLMRequest request) {
        return tokenService.calculateRequestTokens(request)
                .flatMap(tokenInfo -> {
                    // í† í° í•œë„ ì²´í¬
                    if (tokenInfo.getTotalTokens() > getMaxTokensForUser()) {
                        return Mono.error(new TokenLimitExceededException(
                            "Token limit exceeded: " + tokenInfo.getTotalTokens()));
                    }
                    
                    // ê¸°ì¡´ LLM í˜¸ì¶œ (ë™ê¸° ë°©ì‹)
                    return Mono.fromCallable(() -> originalLLMService.generateResponse(request))
                            .subscribeOn(Schedulers.boundedElastic())
                            .map(llmResponse -> LLMResponseWithTokens.builder()
                                    .llmResponse(llmResponse)
                                    .tokenInfo(tokenInfo)
                                    .build());
                });
    }
}
```

## ğŸ¯ WebFlux í™œìš©ì˜ ì¥ì 

### 1. **ë¹„ë™ê¸° ì²˜ë¦¬**
- í† í° ê³„ì‚°ê³¼ LLM í˜¸ì¶œì„ ë³‘ë ¬ë¡œ ì²˜ë¦¬
- ì™¸ë¶€ í† í¬ë‚˜ì´ì € API í˜¸ì¶œ ì‹œ ë…¼ë¸”ë¡œí‚¹

### 2. **ë°±í”„ë ˆì…” ì²˜ë¦¬**
- ëŒ€ëŸ‰ í…ìŠ¤íŠ¸ ë°°ì¹˜ ì²˜ë¦¬ ì‹œ ë©”ëª¨ë¦¬ ë³´í˜¸
- ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì²˜ë¦¬

### 3. **ì—ëŸ¬ ì²˜ë¦¬ ë° Fallback**
- ì™¸ë¶€ API ì‹¤íŒ¨ ì‹œ ë¡œì»¬ í† í¬ë‚˜ì´ì €ë¡œ ìë™ ì „í™˜
- Reactiveí•œ ì—ëŸ¬ í•¸ë“¤ë§

### 4. **ì„±ëŠ¥ ìµœì í™”**
- ë³‘ë ¬ í† í° ê³„ì‚°
- ìºì‹±ê³¼ ê²°í•©í•˜ì—¬ ì„±ëŠ¥ í–¥ìƒ

## ğŸ“Š êµ¬í˜„ ê¶Œì¥ì‚¬í•­

### ìš°ì„ ìˆœìœ„ 1: **ë¡œì»¬ í† í¬ë‚˜ì´ì € (Tiktoken)**
```gradle
implementation 'com.knuddels:jtokkit:0.6.1'
```
- ë¹ ë¥¸ ì²˜ë¦¬ ì†ë„
- ë„¤íŠ¸ì›Œí¬ ë…ë¦½ì 
- OpenAI í˜¸í™˜

### ìš°ì„ ìˆœìœ„ 2: **WebFlux ìŠ¤íŠ¸ë¦¬ë° ë°°ì¹˜ ì²˜ë¦¬**
- ëŒ€ëŸ‰ í…ìŠ¤íŠ¸ ì²˜ë¦¬ ìµœì í™”
- ë©”ëª¨ë¦¬ íš¨ìœ¨ì 

### ìš°ì„ ìˆœìœ„ 3: **ì™¸ë¶€ API Fallback**
- Hugging Face API ì—°ë™
- ë‹¤ì–‘í•œ ëª¨ë¸ ì§€ì›

## ğŸš€ ê²°ë¡ 

**WebFluxë¥¼ í™œìš©í•œ í† í°ëŸ‰ ê³„ì‚° ê¸°ëŠ¥ì€ ì¶©ë¶„íˆ ì¶”ê°€ ê°€ëŠ¥í•˜ë©°, ë‹¤ìŒê³¼ ê°™ì€ ì´ì ì´ ìˆìŠµë‹ˆë‹¤:**

1. âœ… **ê¸°ì¡´ ì•„í‚¤í…ì²˜ì™€ í˜¸í™˜**: í•˜ì´ë¸Œë¦¬ë“œ ë°©ì‹ ìœ ì§€
2. âœ… **ì„±ëŠ¥ í–¥ìƒ**: ë³‘ë ¬ ì²˜ë¦¬ ë° ìŠ¤íŠ¸ë¦¬ë°
3. âœ… **í™•ì¥ì„±**: ë°°ì¹˜ ì²˜ë¦¬ ë° ì™¸ë¶€ API ì—°ë™
4. âœ… **ì‹¤ìš©ì„±**: ë¹„ìš© ê´€ë¦¬ ë° ì‚¬ìš©ëŸ‰ ì œí•œ ê¸°ëŠ¥

ê°€ì¥ ì‹¤ìš©ì ì¸ ì ‘ê·¼ë²•ì€ **ë¡œì»¬ Tiktoken + WebFlux ìŠ¤íŠ¸ë¦¬ë°**ì„ ì¡°í•©í•˜ì—¬ ë¹ ë¥´ê³  ì•ˆì •ì ì¸ í† í° ê³„ì‚° ì„œë¹„ìŠ¤ë¥¼ êµ¬ì¶•í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.